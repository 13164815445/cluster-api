# Cluster API v1.1 compared to v1.2

This document provides an overview over relevant changes between ClusterAPI v1.1 and v1.2 for
maintainers of providers and consumers of our Go API.

## Minimum Kubernetes version for the management cluster

* The minimum Kubernetes version that can be used for a management cluster is now 1.20.0
* The minimum Kubernetes version that can be used for a management cluster with ClusterClass is now 1.22.0

NOTE: compliance with minimum Kubernetes version is enforced both by clusterctl and when the CAPI controller starts. 

## Minimum Go version

* The Go version used by Cluster API is now Go 1.18.x
  * If you are using the gcb-docker-gcloud image in cloudbuild, bump to an image which is using
    Go 1.18, e.g.: `gcr.io/k8s-staging-test-infra/gcb-docker-gcloud:v20220609-2e4c91eb7e`.

## Dependencies

**Note**: Only the most relevant dependencies are listed, `k8s.io/` and `ginkgo`/`gomega` dependencies
in ClusterAPI are kept in sync with the versions used by `sigs.k8s.io/controller-runtime`.

- sigs.k8s.io/controller-tools: v0.8.x => v0.9.x
- sigs.k8s.io/kind: v0.11.x => v0.14.x
- k8s.io/*: v0.23.x => v0.24.x (derived from controller-runtime)
- github.com/onsi/gomega: v0.17.0 => v0.18.1 (derived from controller-runtime)
- k8s.io/kubectl: v0.23.5 => 0.24.0

## Changes by Kind

### Deprecation

* `util.MachinesByCreationTimestamp` has been deprecated and will be removed in a future release.
* the `topology.cluster.x-k8s.io/managed-field-paths` annotation has been deprecated and it will be removed in a future release.

### Removals
* The `third_party/kubernetes-drain` package has been removed, as we're now using `k8s.io/kubectl/pkg/drain` instead ([PR](https://github.com/kubernetes-sigs/cluster-api/pull/5440)).
* `util/version.CompareWithBuildIdentifiers` has been removed, please use `util/version.Compare(a, b, WithBuildTags())` instead.
* The functions `annotations.HasPausedAnnotation` and `annotations.HasSkipRemediationAnnotation` have been removed, please use
  `annotations.HasPaused` and `annotations.HasSkipRemediation` respectively instead.
* `ObjectMeta.ClusterName` has been removed from `k8s.io/apimachinery/pkg/apis/meta/v1`.

### golang API Changes

- `util.ClusterToInfrastructureMapFuncWithExternallyManagedCheck` was removed and the externally managed check was added to `util.ClusterToInfrastructureMapFunc`, which required changing its signature.
   Users of the former simply need to start using the latter and users of the latter need to add the new arguments to their call.

### Required API Changes for providers

- ClusterClass and managed topologies are now using [Server Side Apply](https://kubernetes.io/docs/reference/using-api/server-side-apply/) 
  to properly manage other controllers like CAPA/CAPZ coauthoring slices, see [#6320](https://github.com/kubernetes-sigs/cluster-api/issues/6320).
  In order to take advantage of this feature providers are required to add marker to their API types as described in
  [merge-strategy](https://kubernetes.io/docs/reference/using-api/server-side-apply/#merge-strategy).
  NOTE: the change will cause a rollout on existing clusters created with ClusterClass

E.g. in CAPA

```go
// +optional
Subnets Subnets `json:"subnets,omitempty"
```
Must be modified into:

```go
// +optional
// +listType=map
// +listMapKey=id
Subnets Subnets `json:"subnets,omitempty"
```

### Other

- Logging:
    - To align with the upstream Kubernetes community CAPI now configures logging via `component-base/logs`. 
      This provides advantages like support for the JSON logging format (via `--logging-format=json`) and automatic
      deprecation of klog flags aligned to the upstream Kubernetes deprecation period.
      <details>
      <summary>View <code>main.go</code> diff</summary>

      ```diff
      var (
      	...
      +	logOptions = logs.NewOptions()
      )

      func init() {
      -	klog.InitFlags(nil)

      func InitFlags(fs *pflag.FlagSet) {
      +	logs.AddFlags(fs, logs.SkipLoggingConfigurationFlags())
      +	logOptions.AddFlags(fs)
      
      func main() {
      	...
      	pflag.Parse()
      
      +	if err := logOptions.ValidateAndApply(); err != nil {
      +		setupLog.Error(err, "unable to start manager")
      +		os.Exit(1)
      +	}
      +
      +	// klog.Background will automatically use the right logger.
      +	ctrl.SetLogger(klog.Background())
      -	ctrl.SetLogger(klogr.New())
      ```
      </details>

      This change has been introduced in CAPI in the following PRs: [#6072](https://github.com/kubernetes-sigs/cluster-api/pull/6072), [#6190](https://github.com/kubernetes-sigs/cluster-api/pull/6190).</br>
      **Note**: This change is not mandatory for providers, but highly recommended.

- Following E2E framework functions are now checking that machines are created in the expected failure domain (if defined);
  all E2E tests can now verify failure domains too.
  - `ApplyClusterTemplateAndWait`
  - `WaitForControlPlaneAndMachinesReady`
  - `DiscoveryAndWaitForMachineDeployments`
- The `AssertControlPlaneFailureDomains` function in the E2E test framework has been modified to allow proper failure domain testing.

- After investigating an [issue](https://github.com/kubernetes-sigs/cluster-api/issues/6006) we discovered that improper implementation of a check on `cluster.status.infrastructureReady` can lead to problems during cluster deletion. As a consequence, we recommend that all providers ensure:
  - The check for `cluster.status.infrastructureReady=true` usually existing at the beginning of the reconcile loop for control-plane providers is implemented after setting external objects ref;
  - The check for `cluster.status.infrastructureReady=true` usually existing  at the beginning of the reconcile loop for infrastructure provider does not prevent the object to be deleted  
rif. [PR #6183](https://github.com/kubernetes-sigs/cluster-api/pull/6183)

- CAPI added support for the new control plane label and taint introduced by v1.24 with [PR#5919](https://github.com/kubernetes-sigs/cluster-api/pull/5919).
  Providers should tolerate _both_ `control-plane` and `master` taints for compatibility with v1.24 control planes.
  Further, if they use the label in their `manager.yaml`, it should be adjusted since v1.24 only adds the `node-role.kubernetes.io/control-plane` label.
  An example of such an accommodation can be seen in the capi-provider-aws [manager.yaml][aws-manager-yaml-a69181]

[aws-manager-yaml-a69181]: https://github.com/kubernetes-sigs/cluster-api-provider-aws/blob/a691817f0ea6e8e6624e3c748b33d0058c061fd7/config/manager/manager.yaml?rgh-link-date=2022-02-17T20%3A09%3A43Z#L52